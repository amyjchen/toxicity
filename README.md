# NLP Toxicity Classifier (CS 230 Project)
Amy Chen, Farzaan Kaiyom, Kristen Anderson
Spring 2019

Data is from https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/data

References to code sources can be found in our paper, uploaded to this github as a pdf. 

All code used for models can be found in `scripts`

Our scripts used for error analysis and data augmentation can be found in the `data_aug` folder. More detailed analysis can be found on our Google Team Drive. Please email one of us for access, if you haven't gotten access yet. 
